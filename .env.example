# AIDEFEND MCP Service Configuration
# Copy this file to .env and customize as needed

# GitHub Repository
GITHUB_REPO_OWNER=edward-playground
GITHUB_REPO_NAME=aidefend-framework
GITHUB_BRANCH=main
GITHUB_TACTICS_PATH=tactics

# Sync Configuration
SYNC_INTERVAL_SECONDS=3600
SYNC_TIMEOUT_SECONDS=300
ENABLE_AUTO_SYNC=true

# API Configuration
API_HOST=127.0.0.1
API_PORT=8000

# ⚠️ IMPORTANT: Multi-worker mode is NOT supported
# The sync architecture requires a single worker process.
# Setting API_WORKERS > 1 will cause sync conflicts and stale data issues.
# Keep this value at 1 for correct operation.
API_WORKERS=1

# Security
# MAX_QUERY_LENGTH set to 1500 to align with bge-small-en-v1.5 model's 512 token limit
# (1500 chars ≈ 375 tokens with 4:1 ratio, leaving buffer for system overhead)
MAX_QUERY_LENGTH=1500
MAX_TOP_K=20
DEFAULT_TOP_K=5
ENABLE_RATE_LIMITING=true
RATE_LIMIT_PER_MINUTE=60

# CORS
ENABLE_CORS=true
# CORS_ORIGINS=["http://localhost:*","https://localhost:*"]

# Logging
LOG_LEVEL=INFO
ENABLE_FILE_LOGGING=true

# Advanced: Custom paths (leave as default unless needed)
# DATA_PATH=./data
# DB_PATH=./data/aidefend_kb.lancedb
# RAW_PATH=./data/raw_content
# VERSION_FILE=./data/local_version.json
# LOG_PATH=./data/logs/aidefend_mcp.log

# Advanced: Embedding model (uses FastEmbed with ONNX Runtime)
# Default: BAAI/bge-small-en-v1.5 (lightweight, fast, 384-dim)
# Alternative: sentence-transformers/all-MiniLM-L6-v2 (also supported)
# EMBEDDING_MODEL=BAAI/bge-small-en-v1.5
